name: Continuous Training Pipeline

on:
  push:
    branches: [main, develop]
    paths:
      - 'configs/**'
      - 'src/**'
      - 'scripts/**'
      - 'data/**'
      - '.github/workflows/continuous_training.yml'
  
  pull_request:
    branches: [main, develop]
    paths:
      - 'configs/**'
      - 'src/**'
      - 'scripts/**'
  
  workflow_dispatch:
    inputs:
      config_file:
        description: 'Training configuration file path'
        required: true
        default: 'configs/training_config.yaml'
        type: string
      experiment_name:
        description: 'Experiment name'
        required: false
        type: string
      resume_training:
        description: 'Resume from latest checkpoint'
        required: false
        default: 'true'
        type: boolean
      distributed:
        description: 'Enable distributed training'
        required: false
        default: 'false'
        type: boolean
      world_size:
        description: 'Number of nodes for distributed training'
        required: false
        default: '1'
        type: number
      upload_artifacts:
        description: 'Upload artifacts to cloud storage'
        required: false
        default: 'true'
        type: boolean
      notify_slack:
        description: 'Send Slack notifications'
        required: false
        default: 'true'
        type: boolean
      debug_mode:
        description: 'Enable debug logging'
        required: false
        default: 'false'
        type: boolean
      max_epochs:
        description: 'Maximum number of epochs (overrides config)'
        required: false
        type: number

env:
  PYTHON_VERSION: '3.10'
  CUDA_VERSION: '11.8.0'
  WANDB_PROJECT: 'hrm-training'
  DATA_DIR: 'data/mbpp'
  OUTPUT_BASE_DIR: 'outputs'
  DOCKER_IMAGE: 'hrm-training:latest'
  AWS_REGION: 'us-west-2'
  GCP_PROJECT: 'hrm-research'
  MAX_RETRY_COUNT: 3
  NODE_RANK: 0

jobs:
  validate-config:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install pyyaml jsonschema
      
      - name: Validate configuration
        id: validate
        run: |
          CONFIG_FILE="${{ github.event.inputs.config_file || 'configs/training_config.yaml' }}"
          python scripts/validate_config.py --config-file "$CONFIG_FILE"
          echo "config_file=$CONFIG_FILE" >> $GITHUB_OUTPUT
          
          # Extract experiment name from config if not provided
          if [ -z "${{ github.event.inputs.experiment_name }}" ]; then
            EXPERIMENT_NAME=$(python -c "import yaml; print(yaml.safe_load(open('$CONFIG_FILE'))['experiment_name'])")
            echo "experiment_name=$EXPERIMENT_NAME" >> $GITHUB_OUTPUT
          else
            echo "experiment_name=${{ github.event.inputs.experiment_name }}" >> $GITHUB_OUTPUT
          fi
    outputs:
      config_file: ${{ steps.validate.outputs.config_file }}
      experiment_name: ${{ steps.validate.outputs.experiment_name }}

  prepare-environment:
    needs: validate-config
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-dev.txt
      
      - name: Set up CUDA
        uses: Jimver/cuda-toolkit@v0.2.11
        if: ${{ !github.event.inputs.distributed || github.event.inputs.distributed == 'false' }}
        with:
          cuda: ${{ env.CUDA_VERSION }}
          method: 'network'
          sub-packages: '["nvcc", "cudart", "cublas", "cufft", "curand", "cusolver", "cusparse"]'
      
      - name: Check GPU availability
        id: check-gpu
        run: |
          if command -v nvidia-smi &> /dev/null; then
            echo "gpu_available=true" >> $GITHUB_OUTPUT
            nvidia-smi
          else
            echo "gpu_available=false" >> $GITHUB_OUTPUT
            echo "No GPU available, will use CPU for training"
          fi
      
      - name: Check MPS availability (for Apple Silicon)
        id: check-mps
        run: |
          HAS_MPS=$(python -c "import torch; print('true' if hasattr(torch, 'mps') and torch.mps.is_available() else 'false')")
          echo "mps_available=$HAS_MPS" >> $GITHUB_OUTPUT
          if [ "$HAS_MPS" = "true" ]; then
            echo "Apple MPS is available"
          fi
      
      - name: Set up W&B
        if: ${{ github.event.inputs.notify_slack != 'false' }}
        run: |
          pip install wandb
          wandb login ${{ secrets.WANDB_API_KEY }}
      
      - name: Cache Python dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements*.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
    outputs:
      gpu_available: ${{ steps.check-gpu.outputs.gpu_available }}
      mps_available: ${{ steps.check-mps.outputs.mps_available }}

  download-data:
    needs: [validate-config, prepare-environment]
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests tqdm
      
      - name: Download MBPP dataset
        run: |
          mkdir -p ${{ env.DATA_DIR }}
          python scripts/download_mbpp.py --output-dir ${{ env.DATA_DIR }}
      
      - name: Download baseline models
        run: |
          mkdir -p models/baseline
          python scripts/download_baseline_models.py --output-dir models/baseline
      
      - name: Cache datasets and models
        uses: actions/cache@v3
        with:
          path: |
            ${{ env.DATA_DIR }}
            models/baseline
          key: ${{ runner.os }}-data-${{ hashFiles('scripts/download_*.py') }}
          restore-keys: |
            ${{ runner.os }}-data-

  train:
    needs: [validate-config, prepare-environment, download-data]
    runs-on: ${{ github.event.inputs.distributed == 'true' && 'self-hosted' || 'ubuntu-latest' }}
    strategy:
      fail-fast: false
      matrix:
        node_rank: [0]  # For single-node training
    env:
      EXPERIMENT_NAME: ${{ needs.validate-config.outputs.experiment_name }}
      CONFIG_FILE: ${{ needs.validate-config.outputs.config_file }}
      GPU_AVAILABLE: ${{ needs.prepare-environment.outputs.gpu_available }}
      MPS_AVAILABLE: ${{ needs.prepare-environment.outputs.mps_available }}
      NODE_RANK: ${{ matrix.node_rank }}
      WORLD_SIZE: ${{ github.event.inputs.world_size || '1' }}
      MASTER_ADDR: ${{ matrix.node_rank == 0 && 'localhost' || github.event.inputs.master_addr || 'localhost' }}
      MASTER_PORT: ${{ github.event.inputs.master_port || '12355' }}
      OUTPUT_DIR: ${{ env.OUTPUT_BASE_DIR }}/${{ needs.validate-config.outputs.experiment_name }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
          # Install optional dependencies
          pip install wandb slack_sdk boto3 google-cloud-storage
      
      - name: Set up CUDA
        uses: Jimver/cuda-toolkit@v0.2.11
        if: ${{ env.GPU_AVAILABLE == 'true' }}
        with:
          cuda: ${{ env.CUDA_VERSION }}
          method: 'network'
          sub-packages: '["nvcc", "cudart", "cublas", "cufft", "curand", "cusolver", "cusparse"]'
      
      - name: Restore cached datasets and models
        uses: actions/cache@v3
        with:
          path: |
            ${{ env.DATA_DIR }}
            models/baseline
          key: ${{ runner.os }}-data-${{ hashFiles('scripts/download_*.py') }}
          restore-keys: |
            ${{ runner.os }}-data-
      
      - name: Check for previous checkpoints
        id: check-checkpoints
        run: |
          mkdir -p ${{ env.OUTPUT_DIR }}/checkpoints
          if [ -f "${{ env.OUTPUT_DIR }}/checkpoints/latest.pt" ] && [ "${{ github.event.inputs.resume_training }}" != "false" ]; then
            echo "resume_path=${{ env.OUTPUT_DIR }}/checkpoints/latest.pt" >> $GITHUB_OUTPUT
            echo "Found checkpoint, will resume training"
          else
            echo "resume_path=" >> $GITHUB_OUTPUT
            echo "No checkpoint found or resume disabled, starting fresh"
          fi
      
      - name: Configure AWS credentials
        if: ${{ github.event.inputs.upload_artifacts == 'true' }}
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}
      
      - name: Configure GCP credentials
        if: ${{ github.event.inputs.upload_artifacts == 'true' }}
        uses: google-github-actions/auth@v1
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}
      
      - name: Prepare training command
        id: prepare-command
        run: |
          # Base command
          CMD="python -m scripts.training.training_orchestrator"
          
          # Add config path
          CMD="$CMD --config-path ${{ env.CONFIG_FILE }}"
          
          # Add experiment name
          CMD="$CMD --experiment-name ${{ env.EXPERIMENT_NAME }}"
          
          # Add output directory
          CMD="$CMD --output-dir ${{ env.OUTPUT_DIR }}"
          
          # Add data directory
          CMD="$CMD --data-dir ${{ env.DATA_DIR }}"
          
          # Add resume path if available
          if [ -n "${{ steps.check-checkpoints.outputs.resume_path }}" ]; then
            CMD="$CMD --resume-from ${{ steps.check-checkpoints.outputs.resume_path }}"
          fi
          
          # Add distributed training parameters
          if [ "${{ github.event.inputs.distributed }}" = "true" ]; then
            CMD="$CMD --distributed --world-size ${{ env.WORLD_SIZE }} --node-rank ${{ env.NODE_RANK }} --master-addr ${{ env.MASTER_ADDR }} --master-port ${{ env.MASTER_PORT }}"
          fi
          
          # Add W&B flag
          CMD="$CMD --use-wandb"
          
          # Add notification config
          if [ "${{ github.event.inputs.notify_slack }}" = "true" ]; then
            CMD="$CMD --notification-config slack"
          fi
          
          # Add CI mode flag
          CMD="$CMD --ci-mode"
          
          # Add debug flag
          if [ "${{ github.event.inputs.debug_mode }}" = "true" ]; then
            CMD="$CMD --debug"
          fi
          
          # Add max epochs override
          if [ -n "${{ github.event.inputs.max_epochs }}" ]; then
            CMD="$CMD --max-epochs ${{ github.event.inputs.max_epochs }}"
          fi
          
          echo "command=$CMD" >> $GITHUB_OUTPUT
          echo "Training command: $CMD"
      
      - name: Run training
        id: train
        env:
          WANDB_API_KEY: ${{ secrets.WANDB_API_KEY }}
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          SLACK_API_TOKEN: ${{ secrets.SLACK_API_TOKEN }}
          AWS_S3_BUCKET: ${{ secrets.AWS_S3_BUCKET }}
          GCP_BUCKET: ${{ secrets.GCP_BUCKET }}
        run: |
          # Set environment variables for training
          export WANDB_PROJECT="${{ env.WANDB_PROJECT }}"
          export WANDB_ENTITY="${{ secrets.WANDB_ENTITY }}"
          export PYTHONUNBUFFERED=1
          
          # Create retry mechanism
          MAX_RETRIES=${{ env.MAX_RETRY_COUNT }}
          RETRY_COUNT=0
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            echo "Training attempt $(($RETRY_COUNT + 1))/$MAX_RETRIES"
            
            # Run training command
            ${{ steps.prepare-command.outputs.command }} && TRAINING_SUCCESS=true || TRAINING_SUCCESS=false
            
            if [ "$TRAINING_SUCCESS" = "true" ]; then
              echo "Training completed successfully"
              break
            else
              RETRY_COUNT=$(($RETRY_COUNT + 1))
              if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                echo "Training failed, retrying in 60 seconds..."
                sleep 60
              else
                echo "Training failed after $MAX_RETRIES attempts"
                exit 1
              fi
            fi
          done
      
      - name: Upload checkpoints to S3
        if: ${{ github.event.inputs.upload_artifacts == 'true' && always() }}
        run: |
          aws s3 sync ${{ env.OUTPUT_DIR }}/checkpoints s3://${{ secrets.AWS_S3_BUCKET }}/${{ env.EXPERIMENT_NAME }}/checkpoints/ --exclude "*" --include "*.pt"
          echo "Uploaded checkpoints to S3"
      
      - name: Upload logs to S3
        if: ${{ github.event.inputs.upload_artifacts == 'true' && always() }}
        run: |
          aws s3 sync ${{ env.OUTPUT_DIR }}/logs s3://${{ secrets.AWS_S3_BUCKET }}/${{ env.EXPERIMENT_NAME }}/logs/
          echo "Uploaded logs to S3"
      
      - name: Upload artifacts to GCP
        if: ${{ github.event.inputs.upload_artifacts == 'true' && always() }}
        run: |
          gcloud storage rsync ${{ env.OUTPUT_DIR }}/artifacts gs://${{ secrets.GCP_BUCKET }}/${{ env.EXPERIMENT_NAME }}/artifacts/
          echo "Uploaded artifacts to GCP"
      
      - name: Upload artifacts to GitHub
        if: ${{ always() }}
        uses: actions/upload-artifact@v3
        with:
          name: ${{ env.EXPERIMENT_NAME }}-artifacts
          path: |
            ${{ env.OUTPUT_DIR }}/artifacts/
            ${{ env.OUTPUT_DIR }}/logs/
            ${{ env.OUTPUT_DIR }}/status.json
            ${{ env.OUTPUT_DIR }}/config.yaml
          retention-days: 7
      
      - name: Send training completion notification
        if: ${{ github.event.inputs.notify_slack == 'true' && success() }}
        run: |
          curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"✅ Training completed successfully for experiment *${{ env.EXPERIMENT_NAME }}*\nView results: https://wandb.ai/${{ secrets.WANDB_ENTITY }}/${{ env.WANDB_PROJECT }}/runs/latest\"}" \
            ${{ secrets.SLACK_WEBHOOK_URL }}
      
      - name: Send training failure notification
        if: ${{ github.event.inputs.notify_slack == 'true' && failure() }}
        run: |
          curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"❌ Training failed for experiment *${{ env.EXPERIMENT_NAME }}*\nView logs: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}\"}" \
            ${{ secrets.SLACK_WEBHOOK_URL }}

  distributed-train:
    if: ${{ github.event.inputs.distributed == 'true' && github.event.inputs.world_size > 1 }}
    needs: [validate-config, prepare-environment, download-data]
    runs-on: self-hosted
    strategy:
      fail-fast: false
      matrix:
        node_rank: ${{ fromJson(format('[{0}]', join(github.event.inputs.world_size | map('sequence', 0), ','))) }}
    env:
      EXPERIMENT_NAME: ${{ needs.validate-config.outputs.experiment_name }}
      CONFIG_FILE: ${{ needs.validate-config.outputs.config_file }}
      GPU_AVAILABLE: ${{ needs.prepare-environment.outputs.gpu_available }}
      MPS_AVAILABLE: ${{ needs.prepare-environment.outputs.mps_available }}
      NODE_RANK: ${{ matrix.node_rank }}
      WORLD_SIZE: ${{ github.event.inputs.world_size }}
      MASTER_ADDR: ${{ github.event.inputs.master_addr || 'localhost' }}
      MASTER_PORT: ${{ github.event.inputs.master_port || '12355' }}
      OUTPUT_DIR: ${{ env.OUTPUT_BASE_DIR }}/${{ needs.validate-config.outputs.experiment_name }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          
          # Install optional dependencies
          pip install wandb slack_sdk boto3 google-cloud-storage
      
      - name: Set up CUDA
        uses: Jimver/cuda-toolkit@v0.2.11
        with:
          cuda: ${{ env.CUDA_VERSION }}
          method: 'network'
          sub-packages: '["nvcc", "cudart", "cublas", "cufft", "curand", "cusolver", "cusparse"]'
      
      - name: Restore cached datasets and models
        uses: actions/cache@v3
        with:
          path: |
            ${{ env.DATA_DIR }}
            models/baseline
          key: ${{ runner.os }}-data-${{ hashFiles('scripts/download_*.py') }}
          restore-keys: |
            ${{ runner.os }}-data-
      
      - name: Check for previous checkpoints
        id: check-checkpoints
        run: |
          mkdir -p ${{ env.OUTPUT_DIR }}/checkpoints
          if [ -f "${{ env.OUTPUT_DIR }}/checkpoints/latest.pt" ] && [ "${{ github.event.inputs.resume_training }}" != "false" ]; then
            echo "resume_path=${{ env.OUTPUT_DIR }}/checkpoints/latest.pt" >> $GITHUB_OUTPUT
            echo "Found checkpoint, will resume training"
          else
            echo "resume_path=" >> $GITHUB_OUTPUT
            echo "No checkpoint found or resume disabled, starting fresh"
          fi
      
      - name: Prepare distributed training command
        id: prepare-command
        run: |
          # Base command
          CMD="python -m scripts.training.training_orchestrator"
          
          # Add config path
          CMD="$CMD --config-path ${{ env.CONFIG_FILE }}"
          
          # Add experiment name
          CMD="$CMD --experiment-name ${{ env.EXPERIMENT_NAME }}"
          
          # Add output directory
          CMD="$CMD --output-dir ${{ env.OUTPUT_DIR }}"
          
          # Add data directory
          CMD="$CMD --data-dir ${{ env.DATA_DIR }}"
          
          # Add resume path if available
          if [ -n "${{ steps.check-checkpoints.outputs.resume_path }}" ]; then
            CMD="$CMD --resume-from ${{ steps.check-checkpoints.outputs.resume_path }}"
          fi
          
          # Add distributed training parameters
          CMD="$CMD --distributed --world-size ${{ env.WORLD_SIZE }} --node-rank ${{ env.NODE_RANK }} --master-addr ${{ env.MASTER_ADDR }} --master-port ${{ env.MASTER_PORT }}"
          
          # Add W&B flag (only for master node)
          if [ "${{ env.NODE_RANK }}" = "0" ]; then
            CMD="$CMD --use-wandb"
          fi
          
          # Add notification config (only for master node)
          if [ "${{ github.event.inputs.notify_slack }}" = "true" ] && [ "${{ env.NODE_RANK }}" = "0" ]; then
            CMD="$CMD --notification-config slack"
          fi
          
          # Add CI mode flag
          CMD="$CMD --ci-mode"
          
          # Add debug flag
          if [ "${{ github.event.inputs.debug_mode }}" = "true" ]; then
            CMD="$CMD --debug"
          fi
          
          # Add max epochs override
          if [ -n "${{ github.event.inputs.max_epochs }}" ]; then
            CMD="$CMD --max-epochs ${{ github.event.inputs.max_epochs }}"
          fi
          
          echo "command=$CMD" >> $GITHUB_OUTPUT
          echo "Distributed training command: $CMD"
      
      - name: Run distributed training
        id: train
        env:
          WANDB_API_KEY: ${{ secrets.WANDB_API_KEY }}
          SLACK_WEBHOOK_URL: ${{ secrets.SLACK_WEBHOOK_URL }}
          SLACK_API_TOKEN: ${{ secrets.SLACK_API_TOKEN }}
        run: |
          # Set environment variables for training
          export WANDB_PROJECT="${{ env.WANDB_PROJECT }}"
          export WANDB_ENTITY="${{ secrets.WANDB_ENTITY }}"
          export PYTHONUNBUFFERED=1
          
          # Create retry mechanism
          MAX_RETRIES=${{ env.MAX_RETRY_COUNT }}
          RETRY_COUNT=0
          
          while [ $RETRY_COUNT -lt $MAX_RETRIES ]; do
            echo "Training attempt $(($RETRY_COUNT + 1))/$MAX_RETRIES"
            
            # Run training command
            ${{ steps.prepare-command.outputs.command }} && TRAINING_SUCCESS=true || TRAINING_SUCCESS=false
            
            if [ "$TRAINING_SUCCESS" = "true" ]; then
              echo "Training completed successfully"
              break
            else
              RETRY_COUNT=$(($RETRY_COUNT + 1))
              if [ $RETRY_COUNT -lt $MAX_RETRIES ]; then
                echo "Training failed, retrying in 60 seconds..."
                sleep 60
              else
                echo "Training failed after $MAX_RETRIES attempts"
                exit 1
              fi
            fi
          done
      
      - name: Upload node logs
        if: ${{ always() }}
        uses: actions/upload-artifact@v3
        with:
          name: ${{ env.EXPERIMENT_NAME }}-node-${{ env.NODE_RANK }}-logs
          path: |
            ${{ env.OUTPUT_DIR }}/logs/
          retention-days: 7

  analyze-results:
    needs: [train]
    if: ${{ always() && needs.train.result != 'cancelled' }}
    runs-on: ubuntu-latest
    env:
      EXPERIMENT_NAME: ${{ needs.validate-config.outputs.experiment_name }}
      OUTPUT_DIR: ${{ env.OUTPUT_BASE_DIR }}/${{ needs.validate-config.outputs.experiment_name }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: ${{ env.PYTHON_VERSION }}
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install matplotlib pandas seaborn wandb
      
      - name: Download artifacts
        uses: actions/download-artifact@v3
        with:
          name: ${{ env.EXPERIMENT_NAME }}-artifacts
          path: ${{ env.OUTPUT_DIR }}
      
      - name: Generate training report
        if: ${{ needs.train.result == 'success' }}
        run: |
          python scripts/generate_training_report.py \
            --experiment-name ${{ env.EXPERIMENT_NAME }} \
            --output-dir ${{ env.OUTPUT_DIR }} \
            --wandb-project ${{ env.WANDB_PROJECT }} \
            --wandb-entity ${{ secrets.WANDB_ENTITY }}
      
      - name: Generate failure analysis
        if: ${{ needs.train.result == 'failure' }}
        run: |
          python scripts/analyze_training_failure.py \
            --experiment-name ${{ env.EXPERIMENT_NAME }} \
            --output-dir ${{ env.OUTPUT_DIR }}
      
      - name: Upload report
        uses: actions/upload-artifact@v3
        with:
          name: ${{ env.EXPERIMENT_NAME }}-report
          path: |
            ${{ env.OUTPUT_DIR }}/report/
          retention-days: 30
      
      - name: Send report notification
        if: ${{ github.event.inputs.notify_slack == 'true' && needs.train.result == 'success' }}
        run: |
          curl -X POST -H 'Content-type: application/json' \
            --data "{\"text\":\"📊 Training report available for experiment *${{ env.EXPERIMENT_NAME }}*\nView report: ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}\"}" \
            ${{ secrets.SLACK_WEBHOOK_URL }}
